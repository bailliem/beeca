---
phase: 01-build-validation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: []
autonomous: true

must_haves:
  truths:
    - "R CMD check output is captured and visible"
    - "testthat results are captured and visible"
    - "Any errors, warnings, or failures are clearly identified"
  artifacts:
    - path: ".planning/phases/01-build-validation/01-CHECK-RESULTS.md"
      provides: "R CMD check output and testthat results"
  key_links: []
---

<objective>
Run R CMD check and testthat suite to validate the beeca package builds cleanly.

Purpose: Establish baseline validation status before attempting fixes. Both checks run independently and results are captured for triage.
Output: CHECK-RESULTS.md documenting R CMD check output and testthat results.
</objective>

<execution_context>
@/Users/bailliem/.claude/get-shit-done/workflows/execute-plan.md
@/Users/bailliem/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/01-build-validation/01-CONTEXT.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Run R CMD check</name>
  <files>.planning/phases/01-build-validation/01-CHECK-RESULTS.md</files>
  <action>
Run R CMD check on the beeca package using devtools::check().

1. From the package root directory, run:
   ```r
   Rscript -e "devtools::check(error_on = 'never')"
   ```

2. Capture the full output including:
   - Duration
   - Number of ERRORs
   - Number of WARNINGs
   - Number of NOTEs
   - Details of any issues found

3. Create `.planning/phases/01-build-validation/01-CHECK-RESULTS.md` with a section for R CMD check results.

Note: Use `error_on = 'never'` to capture all issues without stopping on first error. We want complete picture for triage.
  </action>
  <verify>
File 01-CHECK-RESULTS.md exists with R CMD check section showing error/warning/note counts.
  </verify>
  <done>
R CMD check has been run and results are documented with counts of errors, warnings, and notes.
  </done>
</task>

<task type="auto">
  <name>Task 2: Run testthat suite</name>
  <files>.planning/phases/01-build-validation/01-CHECK-RESULTS.md</files>
  <action>
Run the testthat suite for the beeca package.

1. From the package root directory, run:
   ```r
   Rscript -e "devtools::test()"
   ```

2. Capture:
   - Total tests run
   - Tests passed
   - Tests failed
   - Tests skipped
   - Any failure details

3. Append testthat results to `.planning/phases/01-build-validation/01-CHECK-RESULTS.md`.

Note: devtools::test() runs all tests in tests/testthat/. Per context, skip slow cross-validation tests if they exist (check for skip conditions in test files).
  </action>
  <verify>
01-CHECK-RESULTS.md contains testthat section with pass/fail/skip counts.
  </verify>
  <done>
testthat suite has been run and results are documented with pass/fail/skip counts.
  </done>
</task>

<task type="auto">
  <name>Task 3: Summarize validation status</name>
  <files>.planning/phases/01-build-validation/01-CHECK-RESULTS.md</files>
  <action>
Add a summary section to 01-CHECK-RESULTS.md:

1. Create "Validation Summary" section at top of file with:
   - Overall status: PASS (0 errors, 0 warnings, all tests pass) or ISSUES FOUND
   - Quick counts table
   - List of issues requiring triage (if any)

2. If issues found, categorize them:
   - **Blockers**: Errors or test failures that must be fixed
   - **Warnings**: Need evaluation - some may be acceptable
   - **Notes**: Document for awareness, typically don't block release
   - **Skipped tests**: Note why skipped

3. Format the file so it's easy for user to review and make triage decisions.
  </action>
  <verify>
01-CHECK-RESULTS.md has summary section at top with clear status and categorized issues.
  </verify>
  <done>
Validation results are summarized with clear categorization of any issues found.
  </done>
</task>

</tasks>

<verification>
- [ ] R CMD check was run and completed
- [ ] testthat suite was run and completed
- [ ] 01-CHECK-RESULTS.md exists with all results
- [ ] Summary clearly indicates PASS or lists issues for triage
</verification>

<success_criteria>
- R CMD check output captured with error/warning/note counts
- testthat results captured with pass/fail/skip counts
- Results documented in 01-CHECK-RESULTS.md
- Clear summary indicating whether issues need triage in Plan 02
</success_criteria>

<output>
After completion, create `.planning/phases/01-build-validation/01-01-SUMMARY.md`
</output>
