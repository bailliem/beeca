---
phase: 06-gee-testing
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/testthat/test-gee.R
autonomous: true

must_haves:
  truths:
    - "GEE validation tests confirm correct/incorrect models are accepted/rejected for both glmgee and geeglm"
    - "GEE variance estimation matches manual delta method computation (V = D * V_beta * D^T)"
    - "GEE end-to-end pipeline produces correct marginal_results ARD for both GEE packages"
    - "All existing GLM assertions continue to pass without modification (devtools::test() PASS count for GLM tests unchanged)"
    - "R CMD check passes with 0 errors and 0 warnings"
  artifacts:
    - path: "tests/testthat/test-gee.R"
      provides: "GEE-specific test suite (19 test_that blocks)"
      min_lines: 200
  key_links:
    - from: "tests/testthat/test-gee.R"
      to: "R/sanitize.R"
      via: "sanitize_model.glmgee and sanitize_model.geeglm calls"
      pattern: "sanitize_model\\("
    - from: "tests/testthat/test-gee.R"
      to: "R/estimate_varcov.R"
      via: "estimate_varcov with GEE objects and manual delta method cross-validation"
      pattern: "estimate_varcov\\("
    - from: "tests/testthat/test-gee.R"
      to: "R/get_marginal_effect.R"
      via: "end-to-end pipeline producing marginal_results ARD"
      pattern: "get_marginal_effect\\("
---

<objective>
Create a comprehensive GEE test suite, verify zero regressions in existing GLM tests, and confirm R CMD check compliance.

Purpose: Phase 6 validates that the GEE implementation from Phase 5 is correct, covering validation edge cases, variance estimation accuracy (cross-validated against manual delta method computation), and end-to-end pipeline completeness for both glmgee (glmtoolbox) and geeglm (geepack).

Output: tests/testthat/test-gee.R with 19 new test_that blocks, all existing GLM test assertions passing unchanged, R CMD check with 0 errors/0 warnings.
</objective>

<execution_context>
@./.claude/agents/gsd-executor.md
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-gee-testing/06-RESEARCH.md
@.planning/phases/05-gee-core-implementation/05-01-SUMMARY.md
@.planning/phases/05-gee-core-implementation/05-02-SUMMARY.md

Source files under test:
@R/sanitize.R
@R/estimate_varcov.R
@R/get_marginal_effect.R
@R/predict_counterfactuals.R

Existing test patterns to follow:
@tests/testthat/test-sanitize.R
@tests/testthat/test-estimate_varcov.R
@tests/testthat/test-get_marginal_effect.R
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create GEE test suite (test-gee.R)</name>
  <files>tests/testthat/test-gee.R</files>
  <action>
Create `tests/testthat/test-gee.R` with three sections. Follow existing test patterns in test-sanitize.R and test-estimate_varcov.R. Use testthat 3e conventions (no `context()`, use `test_that()` with descriptive names).

**Shared helper at top of file:**

Define `setup_gee_test_data(n = 100, seed = 123)` function that returns a data.frame with columns: id (1:n), trtp (factor with levels "0" and "1", balanced allocation using rep(c("0","1"), each = n/2)), bl_cov (rnorm), aval (rbinom(n, 1, 0.5)).

**Section 1: GEE Validation Tests (~8-10 tests)**

Each test must have `skip_if_not_installed()` followed by `library()` call.

For glmgee (skip_if_not_installed("glmtoolbox")):
1. Valid glmgee model passes sanitize_model -- fit glmgee(aval ~ trtp + bl_cov, id = id, family = binomial(link = "logit"), data = d, corstr = "independence"), call sanitize_model(fit, "trtp"), expect result$sanitized is TRUE.
2. glmgee with wrong family rejected -- use family = poisson(), expect_error with "not in the binomial family with logit link function".
3. glmgee with treatment interaction rejected -- formula aval ~ trtp * bl_cov, expect_error with "treatment-covariate interaction terms".
4. glmgee with multi-timepoint data rejected -- create data where each ID has 2 observations (use rep(1:(n/2), each=2) for id), expect_error with "Multi-timepoint data detected".
5. glmgee with Ye method rejected -- prepare object through average_predictions(), then expect_error on estimate_varcov(method = "Ye") with "Ye's method assumes independence and is not valid for GEE models. Use method='Ge' instead." (use fixed = TRUE).

For geeglm (skip_if_not_installed("geepack")):
6. Valid geeglm model passes sanitize_model -- fit geeglm(aval ~ trtp + bl_cov, id = id, family = binomial(link = "logit"), data = d, corstr = "independence"), call sanitize_model(fit, "trtp"), expect result$sanitized is TRUE.
7. geeglm with wrong family rejected -- similar to glmgee test.
8. geeglm with multi-timepoint data rejected -- similar to glmgee test.

**Section 2: GEE Variance Estimation Tests (~6-8 tests)**

9. glmgee robust variance matches manual delta method computation -- This is the CANONICAL detailed cross-validation test. Use setup_gee_test_data(n = 50, seed = 42). Include extensive comments documenting each step:
   - Fit glmgee model
   - Run beeca pipeline through estimate_varcov(method = "Ge", type = "robust") to get result$robust_varcov
   - INDEPENDENTLY compute expected variance (do NOT use beeca's counterfactual.predictions):
     * Get V_beta = vcov(fit) (GEE's robust variance of coefficients)
     * For each treatment level k in c("0", "1"):
       - Create counterfactual data: set all trtp to level k
       - Build model matrix X_k = model.matrix(formula(fit), counterfactual_data)
       - Compute predictions independently: phat_k = plogis(X_k %*% coef(fit))
       - Compute derivatives: pderiv_k = phat_k * (1 - phat_k)
       - Compute D_k = (t(pderiv_k) %*% X_k) / n
     * Build D = rbind(D_0, D_1)
     * Compute V_manual = D %*% V_beta %*% t(D)
     * Set rownames/colnames to c("0", "1")
   - expect_equal(result$robust_varcov, V_manual, tolerance = 1e-10)
   - Reference: Ge et al (2011) delta method for conditional ATE variance

10. glmgee bias-corrected variance type works -- fit model, call estimate_varcov(method = "Ge", type = "bias-corrected"), verify result$robust_varcov is not NULL, is a matrix, has correct dimnames.

11. glmgee df-adjusted variance type works -- same pattern as bias-corrected but type = "df-adjusted".

12. glmgee with GLM-style variance type produces helpful error -- prepare object through average_predictions(), call estimate_varcov(method = "Ge", type = "HC0"), expect_error with 'Variance type "HC0" is not supported for glmgee objects. Valid types: robust, bias-corrected, df-adjusted' (fixed = TRUE).

13. geeglm robust variance matches manual delta method -- Same independent manual computation pattern as test 9 but with geeglm. Use setup_gee_test_data(n = 50, seed = 42) for identical data. Compute predictions independently via plogis(X %*% coef(fit)), then D %*% vcov(fit) %*% t(D). Compare to beeca result.

14. geeglm with non-robust type produces error -- prepare geeglm through average_predictions(), call estimate_varcov(method = "Ge", type = "bias-corrected"), expect_error with 'Valid types: robust'.

**Section 3: End-to-End Pipeline Tests (~4-6 tests)**

15. glmgee end-to-end with diff contrast -- full get_marginal_effect(fit, trt = "trtp", method = "Ge", type = "robust", contrast = "diff", reference = "0"). Verify: result has class "beeca", marginal_est is not NULL, marginal_se is not NULL, robust_varcov is not NULL, marginal_results is a tibble with 12 rows and 8 columns, no NA values in marginal_results, STAT column contains "contrast".

16. glmgee end-to-end with or contrast -- same but contrast = "or". Verify output structure.

17. geeglm end-to-end with diff contrast -- same pattern as test 15 but with geeglm object.

18. geeglm end-to-end with all five contrast types -- loop through c("diff", "or", "rr", "logor", "logrr"), verify each produces valid marginal_est and marginal_se (both numeric, finite). This confirms Phase 5 success criteria.

19. GEE default type resolution -- call get_marginal_effect on glmgee WITHOUT specifying type (default HC0 should auto-resolve to "robust"). Verify attr(result$robust_varcov, "type") contains "robust" not "HC0".

**Important rules:**
- NEVER modify any existing test file
- Always use set.seed() before generating random test data
- Always pair skip_if_not_installed("pkg") with library(pkg) inside test_that()
- Use id = 1:n for single-timepoint test data
- Only use packages already in Suggests (glmtoolbox, geepack, testthat)
- Add a comment block at the top of the file referencing Ge et al (2011) delta method and explaining the cross-validation approach
  </action>
  <verify>
Run tests with: `Rscript -e "devtools::test(filter = 'gee')"` -- all new GEE tests pass.
Then run full suite: `Rscript -e "devtools::test()"` -- zero failures, zero errors. Record the baseline PASS count from existing GLM tests BEFORE adding GEE tests to verify it remains unchanged after. The PASS count in devtools::test() counts individual assertions (expect_* calls), not test_that() blocks.
  </verify>
  <done>
tests/testthat/test-gee.R exists with ~18-24 tests covering validation (both packages), variance estimation (manual delta method cross-validation, all variance types, error messages), and end-to-end pipeline (multiple contrasts, ARD structure, both packages). All tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: R CMD check compliance gate</name>
  <files>tests/testthat/test-gee.R</files>
  <action>
Run R CMD check via devtools::check() to verify the package passes with 0 errors and 0 warnings.

1. Run: `Rscript -e "devtools::check()"` (may take 2-3 minutes)
2. Examine output for errors and warnings
3. If any errors or warnings appear:
   - Diagnose the issue
   - Fix ONLY in test-gee.R (do NOT modify existing code unless the issue is clearly a pre-existing problem unrelated to GEE tests)
   - Common issues to watch for:
     * Undeclared test dependencies (only use packages in Suggests)
     * Missing skip_if_not_installed() guards
     * Syntax errors in test file
     * Examples that fail when GEE packages not installed
   - Re-run devtools::check() after fixes
4. Notes are acceptable -- document any notes that appear

The target output is:
```
0 errors | 0 warnings | N notes
```
where N can be >= 0.
  </action>
  <verify>
`Rscript -e "devtools::check()"` produces 0 errors and 0 warnings. Capture and report the final check summary line.
  </verify>
  <done>
R CMD check passes with 0 errors and 0 warnings. All existing GLM test assertions pass alongside new GEE tests. Package is ready for Phase 7 (documentation).
  </done>
</task>

</tasks>

<verification>
Phase 6 verification checklist:
1. `tests/testthat/test-gee.R` exists with 18+ tests
2. Tests cover all three sections: validation, variance, end-to-end
3. Manual delta method cross-validation included for both glmgee and geeglm
4. All existing GLM test assertions pass unchanged (baseline PASS count preserved, no modifications to existing test files)
5. All new GEE tests pass
6. R CMD check: 0 errors, 0 warnings
</verification>

<success_criteria>
- TEST-01: test-gee.R exists with tests for validation, variance, and e2e pipeline for both glmgee and geeglm, cross-validated against manual delta method computation
- TEST-02: All existing GLM test assertions pass without modification (baseline PASS count preserved in devtools::test() output)
- TEST-03: R CMD check passes with 0 errors and 0 warnings (verified by devtools::check() output)
</success_criteria>

<output>
After completion, create `.planning/phases/06-gee-testing/06-01-SUMMARY.md`
</output>
