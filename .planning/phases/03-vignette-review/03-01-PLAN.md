---
phase: 03-vignette-review
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - vignettes/estimand_and_implementations.Rmd
autonomous: true

must_haves:
  truths:
    - "Estimand vignette opens with a problem-based hook and teaser code snippet before theory"
    - "A 'Which method should I use?' section maps Ye to PATE and Ge to CPATE with practical guidance"
    - "Primary analysis example uses trial02_cdisc dataset (CDISC ADaM format)"
    - "Comparison section retains trial01 with explicit note explaining why"
    - "Magirr et al. reference updated from OSF preprint to Pharmaceutical Statistics 2025 published version"
    - "No package version numbers in references section"
  artifacts:
    - path: "vignettes/estimand_and_implementations.Rmd"
      provides: "Polished estimand vignette with hook, method guidance, and updated references"
      contains: "Which method should I use"
  key_links:
    - from: "vignettes/estimand_and_implementations.Rmd"
      to: "vignettes/clinical-trial-table.Rmd"
      via: "cross-reference"
      pattern: "vignette.*clinical-trial-table"
    - from: "vignettes/estimand_and_implementations.Rmd"
      to: "vignettes/ard-cards-integration.Rmd"
      via: "cross-reference"
      pattern: "vignette.*ard-cards-integration"
---

<objective>
Polish the estimand_and_implementations vignette: add opening hook with teaser code, add "Which method should I use?" guidance section, switch primary example to trial02_cdisc, update stale references, and add cross-vignette links.

Purpose: The estimand vignette is the "Get Started" entry point in the progressive learning path. It must engage both biostatisticians and programmers from the first paragraph, provide actionable method selection guidance, and use the standardized dataset.

Output: Updated vignettes/estimand_and_implementations.Rmd ready for rendering.
</objective>

<execution_context>
@./.claude/agents/gsd-executor.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-vignette-review/03-CONTEXT.md
@.planning/phases/03-vignette-review/03-RESEARCH.md
@vignettes/estimand_and_implementations.Rmd
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add opening hook, teaser, and "Which method?" section</name>
  <files>vignettes/estimand_and_implementations.Rmd</files>
  <action>
Edit the Introduction section of estimand_and_implementations.Rmd to add a problem-based hook and teaser code snippet BEFORE the current theory content. The hook should:
- Open with the pain point: covariate adjustment is FDA-recommended, but which variance estimator should you use?
- Show a 3-line teaser of beeca in action (using trial02_cdisc)
- Transition naturally into "To understand why this works..." leading to the existing theory

The teaser code should be display-only (not executed) to avoid dependency on the setup chunk. Use a code block with `eval=FALSE` or plain markdown code fence.

Do NOT add explicit "learning objectives" or "prerequisites" boxes (locked decision).
Do NOT remove or alter the existing General Concepts section content — only add new content before it and improve the flow.

After the existing "How to estimate the variance..." subsection (which explains PATE and CPATE), add a new section:

## Which method should I use?

This section should:
- Map Ye et al. (2023) method -> targets PATE (population average treatment effect) -> recommended for most regulatory submissions per FDA guidance on unconditional estimands
- Map Ge et al. (2011) method -> targets CPATE (conditional population average treatment effect) -> appropriate when conditional estimand is of interest
- Provide a simple decision guide: "If in doubt, use method = 'Ye'" with brief rationale
- Note that point estimates are identical between methods; only standard errors differ
- Keep it concise (10-15 lines of prose, no tables needed)
- Cross-reference: "For practical reporting examples, see `vignette('clinical-trial-table')`"
  </action>
  <verify>
Read the file and confirm:
1. Introduction starts with hook paragraph before theory
2. Teaser code snippet present showing beeca usage
3. "Which method should I use?" section exists after PATE/CPATE explanation
4. Cross-reference to clinical-trial-table vignette present
  </verify>
  <done>Estimand vignette opens with engaging hook + teaser, and includes practical method selection guidance</done>
</task>

<task type="auto">
  <name>Task 2: Switch primary example to trial02_cdisc and update references</name>
  <files>vignettes/estimand_and_implementations.Rmd</files>
  <action>
The Analysis Example section (starting at "## Analysis example") already uses trial02_cdisc. Verify this is correct and leave it unchanged.

The Comparison section (starting at "## Comparing different implementations") uses trial01. This is correct and MUST stay as trial01 because cross-validation datasets (margins_trial01, ge_macro_trial01) only exist for trial01. Add an explicit note at the start of the comparison section explaining the dataset switch:

"**Note:** For these cross-validation comparisons, we use the `trial01` dataset (2-arm trial) because pre-computed results from SAS macros (`margins_trial01`, `ge_macro_trial01`) are available for this dataset. The methodology applies identically to `trial02_cdisc`."

Add subheadings within the comparison section to improve scannability. The current structure has "### Ge et al (2011)" and "### Ye et al (2023)". Within the Ge section, add subheadings for each implementation version:

- "#### beeca" (for the beeca_ge call)
- "#### Paper code (Ge et al. 2011)" (for the ge_var_paper function)
- "#### Using {margins}" (for the margins comparison)
- "#### Using {marginaleffects}" (for the marginaleffects comparison)
- "#### SAS %Margins macro" (for the SAS code)

Keep Ge et al. raw paper code inline (locked decision — shows beeca's clean API vs verbose manual code).
Keep all 5 comparisons (locked decision — trust-building feature).

Update the References section at the bottom of the file:

1. Replace Magirr et al. (2024) OSF preprint with published version:
   "Magirr D, Wang C, Przybylski A, Baillie M (2025). Estimating the Variance of Covariate-Adjusted Estimators of Average Treatment Effects in Clinical Trials With Binary Endpoints. *Pharmaceutical Statistics* 24(4): e70021. https://doi.org/10.1002/pst.70021"

2. Also update the inline reference on line ~55 from "[Magirr et al. (2024)](https://osf.io/9mp58/)" to "Magirr et al. (2025)" with the DOI link.

3. Remove version numbers from all package references:
   - marginaleffects: remove "version 0.14.0"
   - margins: remove "version 0.3.26"
   - RobinCar: remove "version 0.2.0"

4. Add DOIs where missing (Ge et al. already has DOI, Ye et al. already has DOI).

5. Add cross-references at the end of the vignette (before References):
   "## Next Steps"
   - For creating clinical trial tables from beeca results: `vignette('clinical-trial-table')`
   - For integrating with the cards ARD framework: `vignette('ard-cards-integration')`
  </action>
  <verify>
Run these checks:
```bash
# Check no OSF/preprint references remain
grep -in "osf.io\|preprint" vignettes/estimand_and_implementations.Rmd
# Should return nothing

# Check no version numbers in package references
grep -n "version [0-9]" vignettes/estimand_and_implementations.Rmd
# Should return nothing

# Check Magirr 2025 reference present
grep -n "Magirr.*2025" vignettes/estimand_and_implementations.Rmd
# Should find the updated reference

# Check cross-references present
grep -n "vignette(" vignettes/estimand_and_implementations.Rmd
# Should find clinical-trial-table and ard-cards-integration references

# Check dataset switch note
grep -n "trial01.*dataset" vignettes/estimand_and_implementations.Rmd
# Should find the explanatory note
```
  </verify>
  <done>Estimand vignette has updated published references (no preprints, no version numbers), comparison subheadings for scannability, dataset switch note, and cross-vignette links</done>
</task>

</tasks>

<verification>
After both tasks:
1. Read the full vignette and confirm narrative flow: hook -> theory -> method guidance -> example -> comparisons -> next steps -> references
2. Confirm trial02_cdisc used in primary example, trial01 in comparisons only (with note)
3. Confirm all locked decisions honored (no learning objectives boxes, Ge paper code inline, all 5 comparisons kept)
</verification>

<success_criteria>
- Estimand vignette opens with problem-based hook + teaser code before any theory
- "Which method should I use?" section exists with clear Ye->PATE, Ge->CPATE mapping
- Magirr et al. updated to Pharmaceutical Statistics 2025 (no OSF links)
- No package version numbers in references
- Comparison section has subheadings for scannability
- trial01 usage in comparison section has explicit explanatory note
- Cross-references to other two vignettes present
</success_criteria>

<output>
After completion, create `.planning/phases/03-vignette-review/03-01-SUMMARY.md`
</output>
